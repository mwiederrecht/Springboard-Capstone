# Springboard Capstone Project"Seamless Pattern Auto-Keywording Web App
### By: Melissa Wiederrecht
---
<br/><br/>
## Motivation:

_If I asked you to provide me with 50 keywords each for the following images that are accurate, commonly searched on stock sites, and comprehensively describe the images, what would you say?  How long would it take you?  Would you miss anything important?_

![Banner of 4 Pattern Images](captone_info/pattern_banner.png)

_Now imagine you were working as a stock image contributer (focusing on seamless patterns) and you were making and uploading at least 500 of these per week.  Keywording has suddenly become a very non-trivial, tedius, and exhausting task._

Image tagging is commonly known to be one of the most successful applications of deep learning in recent years.  So for my Springboard Machine Learning Engineer Career Track Capstone Project I decided to try to make an auto-keyworder for seamless patterns.  Stock sites do already offer machine learning based keyword suggestions during their upload process.  However, such systems must learn to deal with ALL types of stock images that stock sites accept, and as such they are not usually very good at understanding seamless patterns in particular and all the nuances involved in their keywords (in my humble opinion).
<br/><br/>
## Process:

1. **Step 1, Initial Project Ideas:**  In this step I simply brainstormed potential project ideas. ([Link](captone_info/initial_ideas.pdf))
2. **Step 2, Project Proposal:** My project proposal is [here](captone_info/project_proposal.pdf).
3. **Step 3, Data Collection:** I gathered a database of 100k images, keywords (50 each), and descriptions (200 characters each).  This data is private and as such not included here.
4. **Step 4, Data Wrangling:** The code I used to clean and organize the data and images can be seen [here](app/clean_data_and_images.py) and [here](app/clean_images.py).
5. **Step 5, Machine Learning/Deep Learning Prototype:**  The prototype for this project was a binary classification deep learning model that categorized pattern images into "floral" or "stripe".  The code can be seen [here](captone_info/floral_vs_stripes_bestsofar_4.py).
6. **Step 6, Scale Your Prototype:**  After the binary classification, I took several steps to scale my prototype.  I first went for 6-class multi-label classication. Then I did 12-class.  Finally I used 145 classes.  This is the current project that I have arrived at and the model training code is here [here](app/train_model.py).  The 145 classes are listed in [config.py](app/config.py).
7. **Step 7, Deployment Architecture:** I designed a very simple architecture for my deployment, sketched out [here](captone_info/deployment_arch.pdf).
8. **Step 8, End-to-end code with testing:** I converted all notebooks to python files, added logging and unit testing, pulled all constants into [config.py](app/config.py), and organized everything neatly into modules.  This entire repo is the result.  Browse at your leisure.
9. **Step 9, Deployment Implementation:** I implemented [server.py](app/server.py) which servers up both a web interface for predicting with the model and a super-simple API.  I containerized the project in a Docker image and then deployed the project on Render. [See the final result in action and try it out here.](https://springboard-capstone.onrender.com/)
<br/><br/>

<br/><br/>
## Visual Demonstration of Results:

<img src="captone_info\results1.JPG" alt="drawing" width="300"/>
<img src="captone_info\results2.JPG" alt="drawing" width="300"/>
<img src="captone_info\results3.JPG" alt="drawing" width="300"/>
<img src="captone_info\results4.JPG" alt="drawing" width="300"/>
<img src="captone_info\results5.JPG" alt="drawing" width="300"/>
<img src="captone_info\results6.JPG" alt="drawing" width="300"/>

<br/><br/>

> **_NOTE:_** The word 'hand' is part of the word pair 'hand drawn'.  That is what the model must be seeing when it says 'hand'.  In the future I intend to deal with keywords that are more than one word in length properly.  For now, this is what we have.

<br/><br/>

## Remarks

The latest model I have (the included one) has an average accuracy (averaged among all keyword accuracies) of 92%.  This is misleading however, since most of the values for any one keyword are 0.  If you look to the other [metrics](app/models/model-20210317160456894379-18-MCC0_analysis_FULLDATA.csv), the numbers are much lower.  However, in my opinion this is also misleading, since I am dealing with VERY noisy data that was generated by tens of thousands of different people over dozens of years.

I have very often found in my own subjective analysis that the keywords that are recommended by the model are BETTER than those the humans labelled their images with.  Stock image keywording is also a very subjective domain - it is often quite impossible for people to agree if a particular keyword applies to an image or not. (Is it elegant? Beautiful? Romantic? Bohemian? Rustic?).  That being the case, a think a subjective analysis of the results is not entirely uncalled for.

As a microstock contributer myself who is likely to want to use this model in my own work (https://www.shutterstock.com/g/mwiederrecht?sort=popular), I find the keywords that are recommended are very amazingly accurate and useful, and I am very pleased with the results. I am actually blown away by the usefulness of it - it has far exceeded the expectations I had of the project that I had before I started.  I fully intend to train the model and even more keywords going forward and include it into my stock contribution workflow.
<br/><br/>
<br/><br/>
# Local Code Setup

Make sure you have all the required libraries installed (probably in a virtual environment) by opening a command prompt inside the base directory of this project and running:

    pip install -e .

If you want to try the docker image (which presently only works with the server), first make sure you have Docker Desktop installed and then...

To build the docker image and directly run the web app:

    docker build -t keywording-web-app . && docker run --rm -it -p 8080:8080 keywording-web-app

Then go to http://localhost:8080 .

I have provided some images in the test_images folder to make it easy for you to try it.  Or you can find some seamless patterns on the internet (google search 'seamless pattern') and throw them in there and see what you get.


<br/><br/>
# Code Usage

To try out any of the code that I wrote to get to this point, check out the following:

> **_NOTE:_** Run any of the following commands from within the 'app' directory:

<br/><br/>
## Configuration

### To see or adjust configurations, edit config.py

This file contains everything from a list of what classes are being trained/cleaned/served, to what model should be served, to hyperparameters for training, etc.  It is an all-inclusive set of variables to play with.  Change wisely.  (If you change things like the list of classes, the included model WONT work correctly with the code anymore.  You will need to train a new one for the new list.)
<br/><br/><br/><br/>
## Data

The data that the model was trained on has not been included here in this repo.
<br/><br/><br/><br/>
## Data Cleaning

### To Clean the data in the data/csvs_raw and data/images_raw folders, use:

    python clean_data_and_images.py

If you don't want to include all data ever gathered and stored in that folder, be sure to clean out any unwanted csvs first.  Images are only cleaned if they are listed in a csv that is cleaned.  The resulting cleaned csv would appear in data/csvs_ready  and all resulting cleaned images would appear in data/images_ready.  Images that have already been cleaned in the past (and are already in the data/images_ready folder) are ignored and not cleaned again.

### To save out a report of class counts (for each class in CLASSES in config.py and based on the csvs in data/csvs_ready) into reports folder, use:

    python -m fire eda_report.py report_class_counts

Use this of course to check up on class balance.  The report will appear in the reports folder.
<br/><br/><br/><br/>
## Model Training

### To Train a Model

To train a new model based on ResNet50 and initialized wiht imagenet weights, use:

    python -m fire train_model.py train_from_ResNet50_imagenet_weights

To continue training an existing model, which is specified as USE_MODEL in config.py, use:

    python -m fire train_model.py train_from_hdf5_file

To specify a different model to continue training from, use:

    python -m fire train_model.py train_from_hdf5_file --filename="model-20210317160456894379-18-MCC0.58.hdf5"

where the given filename is in the app/models directory
<br/><br/><br/><br/>
## Model Evaluation

### To Evaluate a model and get a console printout, use:

    python -m fire evaluate_model.py evaluate_model --model_file="model-20210317160456894379-18-MCC0.58.hdf5"

where the given filename is in the app/models directory

### To Evaluate a model and get a console printout AND save the analysis into the models directory next to the model file, use:

    python -m fire evaluate_model.py evaluate_model_and_save --model_file="model-20210317160456894379-18-MCC0.58.hdf5"

where the given filename is in the app/models directory

You will get both a printout in the console AND a file in the models directory that saves the results.
<br/><br/><br/><br/>
## Web App

### To start the web app (and API) (on YOUR machine.... not in Docker) which uses the model listed as USE_MODEL in config.py, use:

    python server.py serve

Then visit http://localhost:8080 in your browser.

You can then open any pattern image and hit "Upload & Analyze Image" to get the results.  There are a few test images in the test_images folder you could try, or grab any pattern image off the net (https://www.google.com/search?q=seamless+pattern).  To see the list of keywords the model has been trained on, check out the CLASSES variable in app/config.py

### To use the API when running the server on your local machine...

With the server running (see previous point), open up the command prompt and type:

    curl -X POST -F file=@\"D:\Springboard-Capstone\test_images\70e053e020275c6bf0d3b59ce7307ba2.jpg\" http://localhost:8080/api/predict

You will obviously need to replace the file path and name with the path and name of a file you have on your machine.
