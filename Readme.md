# Springboard Capstone Step 13
## Keywording Web App Deployment Implementation

This is my production ready version of the capstone project.  It includes all steps from data scraping, data cleaning, image cleaning, eda report generation, model training, model evaluation, all the way to the server.py which serves a web interface for predicting keywords for individual images.

(The code has been tested with 70% coverage (see "Test Coverage Report 3-20-2021.JPG").  The code also generates logs in the logs folder.)

I have included a small amount of data (100-ish images per keyword).  I used 50 pages per keyword in the training of the included model, but that data was too large to include here.  The metrics that the code generated to evaluate the current model are in the models folder next to the model.

As you can see in that file, the latest model I have (the included one) has an average accuracy (averaged among all keyword accuracies) of 92%.  This is misleading however, since most of the values for any one keyword are 0.  If you look to the other metrics, the numbers are much lower.  However, in my opinion this is also misleading, since I am dealing with VERY noisy data that was generated by tens of thousands of different people over dozens of years.  I have very often found in my own subjective analysis that the keywords that are recommended by the model are BETTER than those the humans labelled their images with.  Stock image keywording is also a very subjective domain - it is often quite impossible for people to agree if a particular keyword applies to an image or not. (Is it elegant? Beautiful? Romantic? Bohemian? Rustic?).  That being the case, a think a subjective analysis of the results is not entirely uncalled for.  As a microstock contributer myself who is likely to want to use this model in my own work (https://www.shutterstock.com/g/mwiederrecht?sort=popular), I find the keywords that are recommended are very amazingly accurate and useful, and I am very pleased with the results. I am actually blown away by the usefulness of it - it has far exceeded the expectations I had of the project that I had before I started.  I fully intend to train the model and even more keywords going forward and include it into my workflow.


## Setup

Make sure you have all the required libraries installed (probably in a virtual environment) by opening a command prompt inside the base directory of this project and running:

    pip install -e .

If you want to try the docker image (which presently only works with the server), first make sure you have Docker Desktop installed and then...

To build the docker image and directly run the web app:

    docker build -t keywording-web-app . && docker run --rm -it -p 8080:8080 keywording-web-app

Then go to http://localhost:8080 .

I have provided some images in the test_images folder to make it easy for you to try it.  Or you can find some seamless patterns on the internet (google search 'seamless pattern') and throw them in there and see what you get.



## Usage

To try out any of the code that I wrote to get to this point, check out the following:

*** Run any of the following commands from within the 'app' directory:

### To see or adjust configurations, edit config.py

This file contains everything from a list of what classes are being trained/scraped/cleaned/served, to what model should be served, to hyperparameters for training, etc.  It is an all-inclusive set of variables to play with.  Change wisely.  (If you change things like the list of classes, the included model WONT work correctly with the code anymore.  You will need to train a new one for the new list.)

### To Scrape New Data for One Specific Keyword

    python -m fire scrape.py scrape --search_term=seamless+pattern+<SEARCH_TERM> --number_of_pages=<NUMBER_OF_PAGES>

where <SEARCH_TERM> is the keyword you want besides seamless and pattern, 
and <NUMBER_OF_PAGES> is obviously the number of pages you want to scrape.  Each page typically has about 100 images.

For example:

    python -m fire scrape.py scrape --search_term=seamless+pattern+apple --number_of_pages=1
    python -m fire scrape.py scrape --search_term=seamless+pattern+floral --number_of_pages=1

### To Scrape New Data for ALL Classes Listed in CLASSES in config.py

    python -m fire scrape.py scrape_all_classes --pages_per_class=1

Be careful with this one.... there are currently 145 classes listed in the config file.  (Running that for one page per keyword would get you about 6,785 images.)

If for any reason you need to change the user_agent that is passed along with the requests to shutterstock, you can change that in config.py.

### To Clean the data in the data/csvs_raw and data/images_raw folders, use:

    python clean_data_and_images.py

If you don't want to include all data ever gathered and stored in that folder, be sure to clean out any unwanted csvs first.  Images are only cleaned if they are listed in a csv that is cleaned.  The resulting cleaned csv would appear in data/csvs_ready  and all resulting cleaned images would appear in data/images_ready.  Images that have already been cleaned in the past (and are already in the data/images_ready folder) are ignored and not cleaned again.

### To save out a report of class counts (for each class in CLASSES in config.py and based on the csvs in data/csvs_ready) into reports folder, use:

    python -m fire eda_report.py report_class_counts

Use this of course to check up on class balance.  The report will appear in the reports folder.

### To Train a Model

To train a new model based on ResNet50 and initialized wiht imagenet weights, use:

    python -m fire train_model.py train_from_ResNet50_imagenet_weights

To continue training an existing model, which is specified as USE_MODEL in config.py, use:

    python -m fire train_model.py train_from_hdf5_file

To specify a different model to continue training from, use:

    python -m fire train_model.py train_from_hdf5_file --filename="model-20210317160456894379-18-MCC0.58.hdf5"

where the given filename is in the models directory

### To Evaluate a model and get a console printout, use:

    python -m fire evaluate_model.py evaluate_model --model_file="model-20210317160456894379-18-MCC0.58.hdf5"

### To Evaluate a model and get a console printout AND save the analysis into the models directory next to the model file, use:

    python -m fire evaluate_model.py evaluate_model_and_save --model_file="model-20210317160456894379-18-MCC0.58.hdf5"

You will get both a printout in the console AND a file in the models directory that saves the results.

### To start the web app (on YOUR machine.... not in Docker) which uses the model listed as USE_MODEL in config.py, use:

    python server.py serve

Then visit http://localhost:8080 in your browser.

You can then open any pattern image and hit "Upload & Analyze Image" to get the results.  There are a few test images in the test_images folder you could try, or grab any pattern image off the net (https://www.google.com/search?q=seamless+pattern).  To see the list of keywords the model has been trained on, check out the CLASSES variable in app/config.py

### To use the API

With the server running (see previous point), open up the command prompt and type:

    curl -X POST -F file=@\"D:\Springboard-Capstone\test_images\70e053e020275c6bf0d3b59ce7307ba2.jpg\" http://localhost:8080/api/predict

You will obviously need to replace the file path and name with the path and name of a file you have on your machine.
